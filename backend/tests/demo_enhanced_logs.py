#!/usr/bin/env python3
"""
DÃ©monstration du nouveau systÃ¨me de logging centralisÃ© Phase 1.2
Montre les logs gÃ©nÃ©rÃ©s pour debug facile dans Chrome DevTools
"""

import sys
import asyncio
import json
from pathlib import Path
from uuid import uuid4

# Ajouter le chemin du projet pour les imports
sys.path.append(str(Path(__file__).parent))

async def demo_conversation_logging():
    """DÃ©monstration du logging pour les conversations"""
    print("ğŸ¯ DÃ©monstration: Logging des conversations")
    print("=" * 80)
    
    try:
        from app.adapters.outbound.conversation_adapter import ConversationAdapter
        
        adapter = ConversationAdapter()
        
        # Simulation d'une conversation d'apprenant
        learner_session_id = uuid4()
        
        print(f"ğŸ‘¤ Learner Session ID: {learner_session_id}")
        print(f"ğŸ’¬ Message: 'Comment fonctionne le machine learning ?'")
        print(f"ğŸ¯ Action: Conversation avec enrichissement de profil")
        print()
        print("ğŸ“‹ LOGS GÃ‰NÃ‰RÃ‰S (visible dans Chrome DevTools):")
        print("-" * 80)
        
        # Appel qui gÃ©nÃ¨re les logs complets
        result = await adapter.chat_with_learner(
            message="Comment fonctionne le machine learning ?",
            conversation_history=[],
            training_context="Formation Intelligence Artificielle - Module 1: Introduction",
            learner_profile={
                "experience_level": "beginner",
                "job_position": "dÃ©veloppeur web",
                "activity_sector": "technologie",
                "language": "fr",
                "objectives": "comprendre l'IA pour intÃ©grer dans mes projets"
            },
            learner_session_id=learner_session_id
        )
        
        print()
        print("âœ… RÃ©ponse gÃ©nÃ©rÃ©e avec succÃ¨s")
        print(f"ğŸ“ Response preview: {result.get('response', '')[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        return False

async def demo_image_generation_logging():
    """DÃ©monstration du logging pour la gÃ©nÃ©ration d'images"""
    print("\nğŸ¯ DÃ©monstration: Logging DALL-E")
    print("=" * 80)
    
    try:
        from app.adapters.outbound.openai_adapter import OpenAIAdapter
        
        adapter = OpenAIAdapter()
        
        # Simulation de gÃ©nÃ©ration d'infographie
        learner_session_id = uuid4()
        slide_id = uuid4()
        
        print(f"ğŸ‘¤ Learner Session ID: {learner_session_id}")
        print(f"ğŸ–¼ï¸ Slide ID: {slide_id}")
        print(f"ğŸ¨ Action: GÃ©nÃ©ration infographie DALL-E")
        print()
        print("ğŸ“‹ LOGS GÃ‰NÃ‰RÃ‰S (visible dans Chrome DevTools):")
        print("-" * 80)
        
        # Appel qui gÃ©nÃ¨re les logs complets
        result = await adapter.generate_infographic(
            slide_content="Le machine learning utilise des algorithmes pour analyser des donnÃ©es et faire des prÃ©dictions. Les rÃ©seaux de neurones s'inspirent du cerveau humain.",
            slide_title="Introduction au Machine Learning",
            learner_profile={
                "language": "french",
                "experience_level": "intermediate"
            },
            learner_session_id=learner_session_id,
            slide_id=slide_id
        )
        
        print()
        print("âœ… Infographie gÃ©nÃ©rÃ©e avec succÃ¨s")
        print(f"ğŸ–¼ï¸ Image size: {len(result.get('image_data', ''))} base64 chars")
        print(f"âœ¨ Revised prompt: {result.get('revised_prompt', '')[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        return False

def show_log_format_example():
    """Montre le format exact des logs gÃ©nÃ©rÃ©s"""
    print("\nğŸ” Format des logs dans Chrome DevTools")
    print("=" * 80)
    
    print("""
LOGS BACKEND (dans la console du serveur FastAPI):

====================================================================================================
ğŸ¯ [GEMINI_CALL] [INPUT] [CONVERSATION_CHAT] [Session: test_ses... | Learner: 649a485c...]
ğŸ“‹ Call ID: call_3_1754062631
â° Timestamp: 2025-08-01T15:37:17.123456+00:00
ğŸ“ Prompt Length: 2847 characters
ğŸ”§ Context: {
  "prompt_type": "chat",
  "action_type": "chat",
  "generation_config": {
    "temperature": 0.7,
    "top_p": 0.9,
    "max_output_tokens": 2048,
    "response_mime_type": "application/json"
  }
}
-------------------------------------------------- PROMPT START --------------------------------------------------
<ROLE>
Tu es un formateur pÃ©dagogue spÃ©cialisÃ© dans la rÃ©ponse aux [MESSAGE] d'un apprenant...
[PROMPT COMPLET ICI - VISIBLE POUR DEBUG]
</ROLE>
-------------------------------------------------- PROMPT END ----------------------------------------------------
====================================================================================================

====================================================================================================
ğŸ“¥ [GEMINI_CALL] [OUTPUT] [CONVERSATION_CHAT] [Session: test_ses... | Learner: 649a485c...]
ğŸ“‹ Call ID: call_3_1754062631
â° Timestamp: 2025-08-01T15:37:18.456789+00:00
ğŸ“ Response Length: 456 characters
âš¡ Processing Time: 1.333s
ğŸ”§ Metadata: {
  "parsed_successfully": true,
  "action_type": "chat"
}
-------------------------------------------------- RESPONSE START ------------------------------------------------
{
  "response": "Le Machine Learning, c'est donner Ã  un ordinateur la capacitÃ© d'apprendre...",
  "learner_profile": {
    "learning_style_observed": "prÃ©fÃ¨re les explications concrÃ¨tes",
    "comprehension_level": "bon niveau de comprÃ©hension",
    "interests": ["applications pratiques", "exemples concrets"],
    "blockers": ["concepts trop abstraits"],
    "objectives": "intÃ©grer l'IA dans mes projets web",
    "engagement_patterns": "pose des questions prÃ©cises"
  }
}
-------------------------------------------------- RESPONSE END --------------------------------------------------
====================================================================================================

LOGS FRONTEND (dans Chrome DevTools - Ã  implÃ©menter en Phase 2):

[API_CALL] [REQUEST] POST /api/chat - Payload: {...}
[API_CALL] [RESPONSE] 200 OK (1.45s) - Response: {...}
""")

async def main():
    """Fonction principale de dÃ©monstration"""
    print("ğŸš€ DÃ©monstration Logging CentralisÃ© Phase 1.2")
    print("ğŸ“‹ Ce que vous verrez dans les logs de debug...")
    
    # DÃ©monstrations
    await demo_conversation_logging()
    await demo_image_generation_logging()
    
    show_log_format_example()
    
    print("\n" + "=" * 80)
    print("ğŸ‰ Phase 1.2 terminÃ©e avec succÃ¨s !")
    print("âœ… Logging centralisÃ© opÃ©rationnel")
    print("ğŸ” Tous les prompts et rÃ©ponses Gemini sont maintenant visibles")
    print("ğŸ“Š TraÃ§abilitÃ© complÃ¨te avec session IDs")
    print("âš¡ Temps de traitement pour optimisation")
    
    print("\nğŸ“‹ Utilisation:")
    print("1. Lancez votre serveur FastAPI")
    print("2. Utilisez l'app FIA normalement") 
    print("3. Regardez les logs dans la console serveur")
    print("4. Filtrez avec '[GEMINI_CALL]' pour voir uniquement les appels AI")
    print("5. Debug facile avec prompts et rÃ©ponses complÃ¨tes !")

if __name__ == "__main__":
    asyncio.run(main())