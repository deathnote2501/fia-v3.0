#!/usr/bin/env python3
"""
Script de conversation naturelle avec Gemini Live API - VERSION CORRIG√âE
Utilise le microphone pour l'input et les haut-parleurs pour l'output
Permet des interruptions naturelles et une conversation fluide

Pr√©requis:
- Compte Google Cloud avec Vertex AI activ√©
- Authentication Google Cloud (gcloud auth application-default login)
- Installation des d√©pendances (voir instructions ci-dessous)

Installation des d√©pendances:
# Sur Ubuntu
sudo apt-get install portaudio19-dev

# Sur macOS  
brew install portaudio

pip install google-genai pyaudio colorama google-auth google-cloud-core

# Authentication
gcloud auth application-default login
"""

import asyncio
import pyaudio
import signal
import sys
import os
import logging
import traceback
from typing import Optional
from colorama import Fore, Style, init
from google import genai
from google.genai import types
import json
from datetime import datetime

# Initialisation de colorama pour les couleurs dans le terminal
init(autoreset=True)

# Configuration du logging d√©taill√©
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('gemini_live_debug.log')
    ]
)
logger = logging.getLogger(__name__)

def log_debug(message: str, data: any = None):
    """Log de debug avec timestamp et donn√©es optionnelles"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"{Fore.CYAN}[DEBUG {timestamp}] {message}")
    logger.debug(f"{message} - Data: {data if data else 'None'}")

def log_info(message: str):
    """Log d'information"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"{Fore.GREEN}[INFO {timestamp}] {message}")
    logger.info(message)

def log_error(message: str, error: Exception = None):
    """Log d'erreur avec traceback"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"{Fore.RED}[ERROR {timestamp}] {message}")
    logger.error(f"{message} - Error: {error}")
    if error:
        logger.error(traceback.format_exc())

# Configuration du projet (variables en dur pour d√©veloppement local)
GOOGLE_CLOUD_PROJECT = "animemate-ddb62"
GOOGLE_CLOUD_LOCATION = "europe-west1"

# Configuration audio - Optimis√©e pour fluidit√©
CHUNK = 2048  # Augment√© pour plus de fluidit√©
FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
# Mod√®le Live API disponible publiquement
MODEL = 'gemini-2.5-flash-preview-native-audio-dialog'

# Variables globales pour la gestion propre de l'arr√™t
running = True
session = None

class ConversationManager:
    def __init__(self):
        log_info("üîß Initialisation du ConversationManager")
        
        # Test de l'authentification
        self._test_authentication()
        
        log_debug("üì° Cr√©ation du client Vertex AI")
        try:
            self.client = genai.Client(
                vertexai=True,
                project=GOOGLE_CLOUD_PROJECT,
                location=GOOGLE_CLOUD_LOCATION,
            )
            log_info("‚úÖ Client Vertex AI cr√©√© avec succ√®s")
        except Exception as e:
            log_error("‚ùå Erreur cr√©ation client Vertex AI", e)
            raise
        
        log_debug("üéõÔ∏è Configuration de la session Live API")
        # Configuration de la session avec voix fran√ßaise et transcription
        self.config = types.LiveConnectConfig(
            response_modalities=["AUDIO"],
            speech_config=types.SpeechConfig(
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name="Charon",  # Voix masculine fran√ßaise
                        # Alternatives: "Coral" (f√©minine), "River" (neutre)
                    )
                ),
                language_code="fr-FR",
            ),
            input_audio_transcription=types.AudioTranscriptionConfig(),
            output_audio_transcription=types.AudioTranscriptionConfig(),
            system_instruction=types.Content(
                parts=[types.Part(text="""Tu es un assistant IA conversationnel en fran√ßais avec une personnalit√© expressive et adaptative. 
                Adapte ton ton et style de r√©ponse selon l'√©motion et le ton de l'utilisateur :
                - Si l'utilisateur semble joyeux, sois enthousiaste
                - Si l'utilisateur semble inquiet, sois rassurant et calme
                - Si l'utilisateur semble press√©, sois concis et efficace
                - Si l'utilisateur semble d√©tendu, sois conversationnel
                
                R√©ponds de mani√®re naturelle, claire et avec de l'√©motion dans la voix.
                Utilise des expressions fran√ßaises appropri√©es au contexte √©motionnel.
                R√âPONDS TOUJOURS EN FRAN√áAIS DE MANI√àRE NATURELLE ET EXPRESSIVE.""")], 
                role='user'
            ),
            # Configuration pour des r√©ponses plus rapides et fluides
            realtime_input_config=types.RealtimeInputConfig(
                automatic_activity_detection=types.AutomaticActivityDetection(
                    disabled=False,
                    start_of_speech_sensitivity=types.StartSensitivity.START_SENSITIVITY_HIGH,
                    end_of_speech_sensitivity=types.EndSensitivity.END_SENSITIVITY_HIGH,
                    prefix_padding_ms=100,
                    silence_duration_ms=500,
                )
            ),
        )
        log_info("‚úÖ Configuration Live API cr√©√©e")
        
        log_debug("üîä Initialisation interface audio PyAudio")
        try:
            self.audio_interface = pyaudio.PyAudio()
            log_info("‚úÖ Interface audio initialis√©e")
            
            # Affichage des devices audio disponibles
            self._list_audio_devices()
            
        except Exception as e:
            log_error("‚ùå Erreur initialisation audio", e)
            raise
    
    def _test_authentication(self):
        """Test de l'authentification Google Cloud"""
        log_debug("üîê Test de l'authentification Google Cloud")
        try:
            from google.auth import default
            credentials, project = default()
            log_info(f"‚úÖ Authentification OK - Projet d√©tect√©: {project}")
            
            if project != GOOGLE_CLOUD_PROJECT:
                log_debug(f"‚ö†Ô∏è Projet d√©tect√© ({project}) diff√©rent du projet configur√© ({GOOGLE_CLOUD_PROJECT})")
                
        except Exception as e:
            log_error("‚ùå Erreur d'authentification", e)
            print(f"{Fore.RED}üîß Pour corriger l'authentification:")
            print(f"{Fore.YELLOW}   gcloud auth application-default login")
            print(f"{Fore.YELLOW}   gcloud config set project {GOOGLE_CLOUD_PROJECT}")
            raise
    
    def _list_audio_devices(self):
        """Liste les devices audio disponibles"""
        log_debug("üé§ Liste des devices audio disponibles:")
        try:
            info = self.audio_interface.get_host_api_info_by_index(0)
            log_debug(f"API Audio: {info.get('name')}")
            
            for i in range(self.audio_interface.get_device_count()):
                device_info = self.audio_interface.get_device_info_by_index(i)
                log_debug(f"  Device {i}: {device_info.get('name')} "
                         f"(In: {device_info.get('maxInputChannels')}, "
                         f"Out: {device_info.get('maxOutputChannels')})")
                         
        except Exception as e:
            log_error("‚ö†Ô∏è Erreur listage devices audio", e)
        
    async def start_conversation(self):
        """D√©marre une conversation interactive avec Gemini Live API"""
        log_info("üöÄ D√©marrage de la conversation avec Gemini Live API")
        print(f"{Fore.GREEN}üé§ D√©marrage de la conversation avec Gemini Live API...")
        print(f"{Fore.YELLOW}üìù Parlez naturellement, l'IA vous r√©pondra vocalement")
        print(f"{Fore.YELLOW}üõë Ctrl+C pour arr√™ter la conversation")
        print(f"{Fore.CYAN}{'='*60}")
        
        global session
        try:
            log_debug("üì° Tentative de connexion √† Live API")
            log_debug(f"Mod√®le: {MODEL}")
            log_debug(f"Config: {self.config}")
            
            async with self.client.aio.live.connect(model=MODEL, config=self.config) as session:
                log_info("‚úÖ Connexion Live API √©tablie")
                
                # Cr√©ation des t√¢ches asynchrones pour g√©rer les flux audio
                send_task = None
                receive_task = None
                
                try:
                    # D√©marrage des t√¢ches asynchrones
                    log_debug("üîÑ D√©marrage des t√¢ches audio")
                    send_task = asyncio.create_task(self._send_audio())
                    receive_task = asyncio.create_task(self._receive_audio())
                    
                    log_info("üé§ T√¢ches audio d√©marr√©es - Conversation active")
                    
                    # Attendre que les t√¢ches se terminent ou qu'une exception se produise
                    await asyncio.gather(send_task, receive_task, return_exceptions=True)
                    
                except Exception as e:
                    log_error("‚ùå Erreur dans les t√¢ches audio", e)
                    # Annuler les t√¢ches en cours
                    if send_task and not send_task.done():
                        send_task.cancel()
                    if receive_task and not receive_task.done():
                        receive_task.cancel()
                    raise
                
        except Exception as e:
            log_error("‚ùå Erreur lors de la connexion Live API", e)
            print(f"{Fore.RED}‚ùå Erreur lors de la connexion: {e}")
            
            # Diagnostic d√©taill√©
            print(f"{Fore.YELLOW}üîç Diagnostic:")
            print(f"  - Projet: {GOOGLE_CLOUD_PROJECT}")
            print(f"  - R√©gion: {GOOGLE_CLOUD_LOCATION}")
            print(f"  - Mod√®le: {MODEL}")
            
            # Si erreur de mod√®le non trouv√©, sugg√©rer des alternatives
            if "was not fo" in str(e) or "not found" in str(e).lower():
                print(f"{Fore.YELLOW}üí° Le mod√®le Live API n'est pas disponible dans votre projet.")
                print(f"{Fore.YELLOW}   Solutions possibles:")
                print(f"{Fore.YELLOW}   1. Demander l'acc√®s au mod√®le priv√©")
                print(f"{Fore.YELLOW}   2. Contacter votre √©quipe Google Cloud pour l'activation")
                print(f"{Fore.YELLOW}   3. V√©rifier les quotas et limites de votre projet")
            elif "not supported" in str(e).lower():
                print(f"{Fore.YELLOW}üí° Mod√®le non support√© dans Live API.")
                print(f"{Fore.YELLOW}   Solutions:")
                print(f"{Fore.YELLOW}   1. Mod√®le corrig√© vers: {MODEL}")
                print(f"{Fore.YELLOW}   2. V√©rifiez la liste des mod√®les support√©s")
                print(f"{Fore.YELLOW}   3. Utilisez un mod√®le Live API valide")
            
            raise
            
    async def _send_audio(self):
        """Capture et envoie l'audio du microphone - VERSION AM√âLIOR√âE"""
        stream = None
        try:
            log_debug("üé§ Ouverture du stream d'entr√©e audio")
            stream = self.audio_interface.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=INPUT_RATE,
                input=True,
                frames_per_buffer=CHUNK,
                # R√©duction de la latence
                input_device_index=None,  # Utilise le device par d√©faut
            )
            log_info("‚úÖ Stream microphone ouvert")
            
            print(f"{Fore.GREEN}üé§ Microphone activ√© - Vous pouvez commencer √† parler...")
            
            chunk_count = 0
            last_data_time = datetime.now()
            
            while running:
                try:
                    # Lecture non-bloquante du microphone
                    try:
                        frame = stream.read(CHUNK, exception_on_overflow=False)
                        chunk_count += 1
                        
                        # Log p√©riodique pour √©viter le spam
                        if chunk_count % 500 == 0:  # Log tous les 500 chunks (environ toutes les 10 secondes)
                            log_debug(f"üìä Chunk audio #{chunk_count} envoy√© ({len(frame)} bytes)")
                        
                        # Envoi √† Gemini via la session Live API
                        await session.send_realtime_input(
                            audio=types.Blob(data=frame, mime_type="audio/pcm;rate=16000")
                        )
                        
                        last_data_time = datetime.now()
                        
                        # Petite pause pour √©viter la surcharge CPU
                        await asyncio.sleep(0.001)
                        
                    except Exception as read_error:
                        if running:
                            log_error(f"‚ö†Ô∏è Erreur lecture microphone chunk #{chunk_count}", read_error)
                        continue
                        
                except asyncio.CancelledError:
                    log_info("üõë T√¢che d'envoi audio annul√©e")
                    break
                except Exception as e:
                    if running:
                        log_error(f"‚ö†Ô∏è Erreur dans boucle d'envoi audio", e)
                    break
                    
        except Exception as e:
            log_error("‚ùå Erreur ouverture microphone", e)
            print(f"{Fore.RED}‚ùå Impossible d'ouvrir le microphone. V√©rifiez que:")
            print(f"{Fore.YELLOW}   1. Votre microphone est connect√© et fonctionne")
            print(f"{Fore.YELLOW}   2. Aucune autre application n'utilise le microphone")
            print(f"{Fore.YELLOW}   3. Les permissions microphone sont accord√©es")
        finally:
            if stream:
                log_debug("üîê Fermeture du stream microphone")
                try:
                    stream.stop_stream()
                    stream.close()
                    log_info("‚úÖ Stream microphone ferm√©")
                except Exception as close_error:
                    log_error("‚ö†Ô∏è Erreur fermeture microphone", close_error)
                
    async def _receive_audio(self):
        """Re√ßoit et joue l'audio de r√©ponse - VERSION TR√àS AM√âLIOR√âE"""
        output_stream = None
        message_count = 0
        audio_buffer = bytearray()
        
        try:
            log_debug("üîä Ouverture du stream de sortie audio")
            output_stream = self.audio_interface.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=OUTPUT_RATE,
                output=True,
                frames_per_buffer=CHUNK
            )
            log_info("‚úÖ Stream sortie audio ouvert")
            
            log_debug("üëÇ √âcoute des messages Live API")
            async for message in session.receive():
                if not running:
                    break
                    
                message_count += 1
                
                # Log plus s√©lectif pour √©viter le spam
                if message_count % 100 == 0:
                    log_debug(f"üì® Message #{message_count} re√ßu", {
                        'type': type(message).__name__,
                        'has_server_content': hasattr(message, 'server_content') and message.server_content is not None
                    })
                
                # V√©rification de l'existence de server_content
                if not hasattr(message, 'server_content') or not message.server_content:
                    continue
                
                # üîß GESTION DES TRANSCRIPTIONS (am√©lior√©e)
                try:
                    if hasattr(message.server_content, 'input_transcription') and message.server_content.input_transcription:
                        user_text = message.server_content.input_transcription.text
                        if user_text and user_text.strip():
                            log_info(f"üó£Ô∏è Vous avez dit: {user_text}")
                            print(f"{Fore.BLUE}üë§ Vous: {Style.BRIGHT}{user_text}")
                            
                    if hasattr(message.server_content, 'output_transcription') and message.server_content.output_transcription:
                        ai_text = message.server_content.output_transcription.text
                        if ai_text and ai_text.strip():
                            log_info(f"ü§ñ Gemini r√©pond: {ai_text}")
                            print(f"{Fore.MAGENTA}ü§ñ Gemini: {Style.BRIGHT}{ai_text}")
                except Exception as transcription_error:
                    log_error("‚ö†Ô∏è Erreur traitement transcription", transcription_error)
                        
                # üîß GESTION DES INTERRUPTIONS (simplifi√©e et robuste)
                try:
                    if hasattr(message.server_content, 'interrupted') and message.server_content.interrupted:
                        log_info("‚è∏Ô∏è Interruption d√©tect√©e - Nettoyage buffer audio")
                        print(f"{Fore.YELLOW}‚è∏Ô∏è Interruption d√©tect√©e - Vous pouvez parler")
                        
                        # Vider le buffer audio seulement
                        audio_buffer.clear()
                        continue
                except Exception as interrupt_error:
                    log_error("‚ö†Ô∏è Erreur gestion interruption", interrupt_error)
                        
                # üîß GESTION DE L'AUDIO DE R√âPONSE (tr√®s am√©lior√©e)
                try:
                    if hasattr(message.server_content, 'model_turn') and message.server_content.model_turn:
                        model_turn = message.server_content.model_turn
                        
                        for part_idx, part in enumerate(model_turn.parts):
                            if hasattr(part, 'inline_data') and part.inline_data and part.inline_data.data:
                                try:
                                    audio_data = part.inline_data.data
                                    audio_size = len(audio_data)
                                    
                                    # Log s√©lectif pour √©viter le spam
                                    if part_idx % 10 == 0:
                                        log_debug(f"üîä Audio part #{part_idx} re√ßu ({audio_size} bytes)")
                                    
                                    # Ajouter au buffer pour un rendu fluide
                                    audio_buffer.extend(audio_data)
                                    
                                    # Lecture par chunks pour fluidit√©
                                    min_buffer_size = CHUNK * 2  # Buffer minimum r√©duit pour moins de latence
                                    while len(audio_buffer) >= min_buffer_size and output_stream and running:
                                        # Extraire un chunk du buffer
                                        chunk_to_play = bytes(audio_buffer[:min_buffer_size])
                                        audio_buffer = audio_buffer[min_buffer_size:]
                                        
                                        # Jouer le chunk
                                        try:
                                            output_stream.write(chunk_to_play)
                                            await asyncio.sleep(0.001)  # Micro-pause pour fluidit√©
                                        except Exception as play_error:
                                            log_error(f"‚ö†Ô∏è Erreur lecture chunk audio", play_error)
                                            break
                                            
                                except Exception as audio_error:
                                    if running:
                                        log_error(f"‚ö†Ô∏è Erreur traitement audio part #{part_idx}", audio_error)
                                        
                        # Jouer le buffer restant √† la fin du tour de mod√®le
                        if len(audio_buffer) > 0 and output_stream and running:
                            try:
                                # Compl√©ter avec du silence si n√©cessaire pour alignment
                                while len(audio_buffer) % 2 != 0:
                                    audio_buffer.append(0)
                                    
                                output_stream.write(bytes(audio_buffer))
                                audio_buffer.clear()
                            except Exception as final_audio_error:
                                if running:
                                    log_error("‚ö†Ô∏è Erreur lecture buffer final", final_audio_error)
                                    
                except Exception as model_turn_error:
                    log_error("‚ö†Ô∏è Erreur traitement model_turn", model_turn_error)
                        
        except asyncio.CancelledError:
            log_info("üõë T√¢che de r√©ception audio annul√©e")
        except Exception as e:
            if running:
                log_error("‚ùå Erreur r√©ception audio", e)
        finally:
            # Jouer le buffer restant avant fermeture
            if len(audio_buffer) > 0 and output_stream:
                try:
                    while len(audio_buffer) % 2 != 0:
                        audio_buffer.append(0)
                    output_stream.write(bytes(audio_buffer))
                    log_debug(f"üîä Buffer final jou√© ({len(audio_buffer)} bytes)")
                except Exception as final_error:
                    log_error("‚ö†Ô∏è Erreur buffer final", final_error)
                    
            # Fermeture propre du stream
            if output_stream:
                log_debug("üîê Fermeture du stream sortie audio")
                try:
                    output_stream.stop_stream()
                    output_stream.close()
                    log_info("‚úÖ Stream sortie audio ferm√©")
                except Exception as close_error:
                    log_error("‚ö†Ô∏è Erreur fermeture stream sortie", close_error)
                
    def cleanup(self):
        """Nettoyage des ressources"""
        log_debug("üßπ Nettoyage des ressources")
        try:
            self.audio_interface.terminate()
            log_info("‚úÖ Ressources audio lib√©r√©es")
            print(f"{Fore.GREEN}‚úÖ Ressources audio lib√©r√©es")
        except Exception as e:
            log_error("‚ö†Ô∏è Erreur lors du nettoyage", e)
            print(f"{Fore.RED}‚ö†Ô∏è Erreur lors du nettoyage: {e}")

def signal_handler(signum, frame):
    """Gestionnaire pour arr√™t propre avec Ctrl+C"""
    global running
    log_info("üõë Signal d'arr√™t re√ßu")
    print(f"\n{Fore.YELLOW}üõë Arr√™t de la conversation...")
    running = False

def main():
    """Fonction principale"""
    log_info("üöÄ D√©marrage de l'application Gemini Live API")
    
    # Configuration directe (variables en dur pour d√©veloppement local)
    project_id = GOOGLE_CLOUD_PROJECT
    location = GOOGLE_CLOUD_LOCATION
    
    print(f"{Fore.GREEN}‚úÖ Configuration charg√©e:")
    print(f"{Fore.GREEN}   GOOGLE_CLOUD_PROJECT={project_id}")
    print(f"{Fore.GREEN}   GOOGLE_CLOUD_LOCATION={location}")
    print(f"{Fore.GREEN}   MODEL={MODEL}")
    
    log_debug("Configuration syst√®me", {
        'project': project_id,
        'location': location,
        'model': MODEL,
        'python_version': sys.version,
        'working_directory': os.getcwd()
    })
    
    # Configuration du gestionnaire de signal pour Ctrl+C
    signal.signal(signal.SIGINT, signal_handler)
    log_debug("üîß Gestionnaire de signal configur√©")
    
    # Initialisation et d√©marrage
    conversation = None
    try:
        log_debug("üèóÔ∏è Cr√©ation du ConversationManager")
        conversation = ConversationManager()
        
        print(f"{Fore.CYAN}üöÄ Initialisation de la conversation avec Gemini Live API")
        print(f"{Fore.CYAN}üìç Projet: {project_id}")
        print(f"{Fore.CYAN}üåç R√©gion: {location}")
        print(f"{Fore.CYAN}ü§ñ Mod√®le: {MODEL}")
        
        log_info("‚ñ∂Ô∏è Lancement de la conversation")
        asyncio.run(conversation.start_conversation())
        
    except KeyboardInterrupt:
        log_info("üõë Conversation interrompue par l'utilisateur")
        print(f"\n{Fore.YELLOW}üõë Conversation interrompue par l'utilisateur")
    except Exception as e:
        log_error("‚ùå Erreur inattendue", e)
        print(f"{Fore.RED}‚ùå Erreur inattendue: {e}")
        print(f"{Fore.YELLOW}üìã Consultez le fichier 'gemini_live_debug.log' pour plus de d√©tails")
    finally:
        if conversation:
            conversation.cleanup()
        log_info("üëã Fin de l'application")
        print(f"{Fore.GREEN}üëã Au revoir !")

if __name__ == "__main__":
    main()