#!/usr/bin/env python3
"""
Script de conversation naturelle avec Gemini Live API - VERSION CORRIGÃ‰E
Utilise le microphone pour l'input et les haut-parleurs pour l'output
Permet des interruptions naturelles et une conversation fluide

PrÃ©requis:
- Compte Google Cloud avec Vertex AI activÃ©
- Authentication Google Cloud (gcloud auth application-default login)
- Installation des dÃ©pendances (voir instructions ci-dessous)

Installation des dÃ©pendances:
# Sur Ubuntu
sudo apt-get install portaudio19-dev

# Sur macOS  
brew install portaudio

pip install google-genai pyaudio colorama google-auth google-cloud-core

# Authentication
gcloud auth application-default login
"""

import asyncio
import pyaudio
import signal
import sys
import os
import logging
import traceback
from typing import Optional
from colorama import Fore, Style, init
from google import genai
from google.genai import types
import json
from datetime import datetime

# Initialisation de colorama pour les couleurs dans le terminal
init(autoreset=True)

# Configuration du logging dÃ©taillÃ©
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('gemini_live_debug.log')
    ]
)
logger = logging.getLogger(__name__)

def log_debug(message: str, data: any = None):
    """Log de debug avec timestamp et donnÃ©es optionnelles"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"{Fore.CYAN}[DEBUG {timestamp}] {message}")
    logger.debug(f"{message} - Data: {data if data else 'None'}")

def log_info(message: str):
    """Log d'information"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"{Fore.GREEN}[INFO {timestamp}] {message}")
    logger.info(message)

def log_error(message: str, error: Exception = None):
    """Log d'erreur avec traceback"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    print(f"{Fore.RED}[ERROR {timestamp}] {message}")
    logger.error(f"{message} - Error: {error}")
    if error:
        logger.error(traceback.format_exc())

# Configuration du projet (variables en dur pour dÃ©veloppement local)
GOOGLE_CLOUD_PROJECT = "animemate-ddb62"
GOOGLE_CLOUD_LOCATION = "europe-west1"

# Configuration audio - OptimisÃ©e pour fluiditÃ©
CHUNK = 2048  # AugmentÃ© pour plus de fluiditÃ©
FORMAT = pyaudio.paInt16
CHANNELS = 1
INPUT_RATE = 16000
OUTPUT_RATE = 24000
# ModÃ¨le Live API disponible publiquement
MODEL = 'gemini-2.5-flash-preview-native-audio-dialog'

# Variables globales pour la gestion propre de l'arrÃªt
running = True
session = None

class ConversationManager:
    def __init__(self):
        log_info("ğŸ”§ Initialisation du ConversationManager")
        
        # Test de l'authentification
        self._test_authentication()
        
        log_debug("ğŸ“¡ CrÃ©ation du client Vertex AI")
        try:
            self.client = genai.Client(
                vertexai=True,
                project=GOOGLE_CLOUD_PROJECT,
                location=GOOGLE_CLOUD_LOCATION,
            )
            log_info("âœ… Client Vertex AI crÃ©Ã© avec succÃ¨s")
        except Exception as e:
            log_error("âŒ Erreur crÃ©ation client Vertex AI", e)
            raise
        
        log_debug("ğŸ›ï¸ Configuration de la session Live API")
        # Configuration de la session avec voix franÃ§aise et transcription
        self.config = types.LiveConnectConfig(
            response_modalities=["AUDIO"],
            speech_config=types.SpeechConfig(
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name="Charon",  # Voix masculine franÃ§aise
                        # Alternatives: "Coral" (fÃ©minine), "River" (neutre)
                    )
                ),
                language_code="fr-FR",
            ),
            input_audio_transcription=types.AudioTranscriptionConfig(),
            output_audio_transcription=types.AudioTranscriptionConfig(),
            system_instruction=types.Content(
                parts=[types.Part(text="""Tu es un assistant IA conversationnel en franÃ§ais avec une personnalitÃ© expressive et adaptative. 
                Adapte ton ton et style de rÃ©ponse selon l'Ã©motion et le ton de l'utilisateur :
                - Si l'utilisateur semble joyeux, sois enthousiaste
                - Si l'utilisateur semble inquiet, sois rassurant et calme
                - Si l'utilisateur semble pressÃ©, sois concis et efficace
                - Si l'utilisateur semble dÃ©tendu, sois conversationnel
                
                RÃ©ponds de maniÃ¨re naturelle, claire et avec de l'Ã©motion dans la voix.
                Utilise des expressions franÃ§aises appropriÃ©es au contexte Ã©motionnel.
                RÃ‰PONDS TOUJOURS EN FRANÃ‡AIS DE MANIÃˆRE NATURELLE ET EXPRESSIVE.""")], 
                role='user'
            ),
            # Configuration pour des rÃ©ponses plus rapides et fluides
            realtime_input_config=types.RealtimeInputConfig(
                automatic_activity_detection=types.AutomaticActivityDetection(
                    disabled=False,
                    start_of_speech_sensitivity=types.StartSensitivity.START_SENSITIVITY_HIGH,
                    end_of_speech_sensitivity=types.EndSensitivity.END_SENSITIVITY_HIGH,
                    prefix_padding_ms=100,
                    silence_duration_ms=500,
                )
            ),
        )
        log_info("âœ… Configuration Live API crÃ©Ã©e")
        
        log_debug("ğŸ”Š Initialisation interface audio PyAudio")
        try:
            self.audio_interface = pyaudio.PyAudio()
            log_info("âœ… Interface audio initialisÃ©e")
            
            # Affichage des devices audio disponibles
            self._list_audio_devices()
            
        except Exception as e:
            log_error("âŒ Erreur initialisation audio", e)
            raise
    
    def _test_authentication(self):
        """Test de l'authentification Google Cloud"""
        log_debug("ğŸ” Test de l'authentification Google Cloud")
        try:
            from google.auth import default
            credentials, project = default()
            log_info(f"âœ… Authentification OK - Projet dÃ©tectÃ©: {project}")
            
            if project != GOOGLE_CLOUD_PROJECT:
                log_debug(f"âš ï¸ Projet dÃ©tectÃ© ({project}) diffÃ©rent du projet configurÃ© ({GOOGLE_CLOUD_PROJECT})")
                
        except Exception as e:
            log_error("âŒ Erreur d'authentification", e)
            print(f"{Fore.RED}ğŸ”§ Pour corriger l'authentification:")
            print(f"{Fore.YELLOW}   gcloud auth application-default login")
            print(f"{Fore.YELLOW}   gcloud config set project {GOOGLE_CLOUD_PROJECT}")
            raise
    
    def _list_audio_devices(self):
        """Liste les devices audio disponibles"""
        log_debug("ğŸ¤ Liste des devices audio disponibles:")
        try:
            info = self.audio_interface.get_host_api_info_by_index(0)
            log_debug(f"API Audio: {info.get('name')}")
            
            for i in range(self.audio_interface.get_device_count()):
                device_info = self.audio_interface.get_device_info_by_index(i)
                log_debug(f"  Device {i}: {device_info.get('name')} "
                         f"(In: {device_info.get('maxInputChannels')}, "
                         f"Out: {device_info.get('maxOutputChannels')})")
                         
        except Exception as e:
            log_error("âš ï¸ Erreur listage devices audio", e)
        
    async def start_conversation(self):
        """DÃ©marre une conversation interactive avec Gemini Live API"""
        log_info("ğŸš€ DÃ©marrage de la conversation avec Gemini Live API")
        print(f"{Fore.GREEN}ğŸ¤ DÃ©marrage de la conversation avec Gemini Live API...")
        print(f"{Fore.YELLOW}ğŸ“ Parlez naturellement, l'IA vous rÃ©pondra vocalement")
        print(f"{Fore.YELLOW}ğŸ›‘ Ctrl+C pour arrÃªter la conversation")
        print(f"{Fore.CYAN}{'='*60}")
        
        global session
        try:
            log_debug("ğŸ“¡ Tentative de connexion Ã  Live API")
            log_debug(f"ModÃ¨le: {MODEL}")
            log_debug(f"Config: {self.config}")
            
            async with self.client.aio.live.connect(model=MODEL, config=self.config) as session:
                log_info("âœ… Connexion Live API Ã©tablie")
                
                # CrÃ©ation des tÃ¢ches asynchrones pour gÃ©rer les flux audio
                send_task = None
                receive_task = None
                
                try:
                    # DÃ©marrage des tÃ¢ches asynchrones
                    log_debug("ğŸ”„ DÃ©marrage des tÃ¢ches audio")
                    send_task = asyncio.create_task(self._send_audio())
                    receive_task = asyncio.create_task(self._receive_audio())
                    
                    log_info("ğŸ¤ TÃ¢ches audio dÃ©marrÃ©es - Conversation active")
                    
                    # Attendre que les tÃ¢ches se terminent ou qu'une exception se produise
                    await asyncio.gather(send_task, receive_task, return_exceptions=True)
                    
                except Exception as e:
                    log_error("âŒ Erreur dans les tÃ¢ches audio", e)
                    # Annuler les tÃ¢ches en cours
                    if send_task and not send_task.done():
                        send_task.cancel()
                    if receive_task and not receive_task.done():
                        receive_task.cancel()
                    raise
                
        except Exception as e:
            log_error("âŒ Erreur lors de la connexion Live API", e)
            print(f"{Fore.RED}âŒ Erreur lors de la connexion: {e}")
            
            # Diagnostic dÃ©taillÃ©
            print(f"{Fore.YELLOW}ğŸ” Diagnostic:")
            print(f"  - Projet: {GOOGLE_CLOUD_PROJECT}")
            print(f"  - RÃ©gion: {GOOGLE_CLOUD_LOCATION}")
            print(f"  - ModÃ¨le: {MODEL}")
            
            # Si erreur de modÃ¨le non trouvÃ©, suggÃ©rer des alternatives
            if "was not fo" in str(e) or "not found" in str(e).lower():
                print(f"{Fore.YELLOW}ğŸ’¡ Le modÃ¨le Live API n'est pas disponible dans votre projet.")
                print(f"{Fore.YELLOW}   Solutions possibles:")
                print(f"{Fore.YELLOW}   1. Demander l'accÃ¨s au modÃ¨le privÃ©")
                print(f"{Fore.YELLOW}   2. Contacter votre Ã©quipe Google Cloud pour l'activation")
                print(f"{Fore.YELLOW}   3. VÃ©rifier les quotas et limites de votre projet")
            elif "not supported" in str(e).lower():
                print(f"{Fore.YELLOW}ğŸ’¡ ModÃ¨le non supportÃ© dans Live API.")
                print(f"{Fore.YELLOW}   Solutions:")
                print(f"{Fore.YELLOW}   1. ModÃ¨le corrigÃ© vers: {MODEL}")
                print(f"{Fore.YELLOW}   2. VÃ©rifiez la liste des modÃ¨les supportÃ©s")
                print(f"{Fore.YELLOW}   3. Utilisez un modÃ¨le Live API valide")
            
            raise
            
    async def _send_audio(self):
        """Capture et envoie l'audio du microphone - VERSION AMÃ‰LIORÃ‰E"""
        stream = None
        try:
            log_debug("ğŸ¤ Ouverture du stream d'entrÃ©e audio")
            stream = self.audio_interface.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=INPUT_RATE,
                input=True,
                frames_per_buffer=CHUNK,
                # RÃ©duction de la latence
                input_device_index=None,  # Utilise le device par dÃ©faut
            )
            log_info("âœ… Stream microphone ouvert")
            
            print(f"{Fore.GREEN}ğŸ¤ Microphone activÃ© - Vous pouvez commencer Ã  parler...")
            
            chunk_count = 0
            last_data_time = datetime.now()
            
            while running:
                try:
                    # Lecture non-bloquante du microphone
                    try:
                        frame = stream.read(CHUNK, exception_on_overflow=False)
                        chunk_count += 1
                        
                        # Log pÃ©riodique pour Ã©viter le spam
                        if chunk_count % 500 == 0:  # Log tous les 500 chunks (environ toutes les 10 secondes)
                            log_debug(f"ğŸ“Š Chunk audio #{chunk_count} envoyÃ© ({len(frame)} bytes)")
                        
                        # Envoi Ã  Gemini via la session Live API
                        await session.send_realtime_input(
                            audio=types.Blob(data=frame, mime_type="audio/pcm;rate=16000")
                        )
                        
                        last_data_time = datetime.now()
                        
                        # Petite pause pour Ã©viter la surcharge CPU
                        await asyncio.sleep(0.001)
                        
                    except Exception as read_error:
                        if running:
                            log_error(f"âš ï¸ Erreur lecture microphone chunk #{chunk_count}", read_error)
                        continue
                        
                except asyncio.CancelledError:
                    log_info("ğŸ›‘ TÃ¢che d'envoi audio annulÃ©e")
                    break
                except Exception as e:
                    if running:
                        log_error(f"âš ï¸ Erreur dans boucle d'envoi audio", e)
                    break
                    
        except Exception as e:
            log_error("âŒ Erreur ouverture microphone", e)
            print(f"{Fore.RED}âŒ Impossible d'ouvrir le microphone. VÃ©rifiez que:")
            print(f"{Fore.YELLOW}   1. Votre microphone est connectÃ© et fonctionne")
            print(f"{Fore.YELLOW}   2. Aucune autre application n'utilise le microphone")
            print(f"{Fore.YELLOW}   3. Les permissions microphone sont accordÃ©es")
        finally:
            if stream:
                log_debug("ğŸ” Fermeture du stream microphone")
                try:
                    stream.stop_stream()
                    stream.close()
                    log_info("âœ… Stream microphone fermÃ©")
                except Exception as close_error:
                    log_error("âš ï¸ Erreur fermeture microphone", close_error)
                
    async def _receive_audio(self):
        """ReÃ§oit et joue l'audio de rÃ©ponse - VERSION TRÃˆS AMÃ‰LIORÃ‰E"""
        output_stream = None
        message_count = 0
        audio_buffer = bytearray()
        
        try:
            log_debug("ğŸ”Š Ouverture du stream de sortie audio")
            output_stream = self.audio_interface.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=OUTPUT_RATE,
                output=True,
                frames_per_buffer=CHUNK
            )
            log_info("âœ… Stream sortie audio ouvert")
            
            log_debug("ğŸ‘‚ Ã‰coute des messages Live API")
            async for message in session.receive():
                if not running:
                    break
                    
                message_count += 1
                
                # Log plus sÃ©lectif pour Ã©viter le spam
                if message_count % 100 == 0:
                    log_debug(f"ğŸ“¨ Message #{message_count} reÃ§u", {
                        'type': type(message).__name__,
                        'has_server_content': hasattr(message, 'server_content') and message.server_content is not None
                    })
                
                # VÃ©rification de l'existence de server_content
                if not hasattr(message, 'server_content') or not message.server_content:
                    continue
                
                # ğŸ”§ GESTION DES TRANSCRIPTIONS (amÃ©liorÃ©e)
                try:
                    if hasattr(message.server_content, 'input_transcription') and message.server_content.input_transcription:
                        user_text = message.server_content.input_transcription.text
                        if user_text and user_text.strip():
                            log_info(f"ğŸ—£ï¸ Vous avez dit: {user_text}")
                            print(f"{Fore.BLUE}ğŸ‘¤ Vous: {Style.BRIGHT}{user_text}")
                            
                    if hasattr(message.server_content, 'output_transcription') and message.server_content.output_transcription:
                        ai_text = message.server_content.output_transcription.text
                        if ai_text and ai_text.strip():
                            log_info(f"ğŸ¤– Gemini rÃ©pond: {ai_text}")
                            print(f"{Fore.MAGENTA}ğŸ¤– Gemini: {Style.BRIGHT}{ai_text}")
                except Exception as transcription_error:
                    log_error("âš ï¸ Erreur traitement transcription", transcription_error)
                        
                # ğŸ”§ GESTION DES INTERRUPTIONS (simplifiÃ©e et robuste)
                try:
                    if hasattr(message.server_content, 'interrupted') and message.server_content.interrupted:
                        log_info("â¸ï¸ Interruption dÃ©tectÃ©e - Nettoyage buffer audio")
                        print(f"{Fore.YELLOW}â¸ï¸ Interruption dÃ©tectÃ©e - Vous pouvez parler")
                        
                        # Vider le buffer audio seulement
                        audio_buffer.clear()
                        continue
                except Exception as interrupt_error:
                    log_error("âš ï¸ Erreur gestion interruption", interrupt_error)
                        
                # ğŸ”§ GESTION DE L'AUDIO DE RÃ‰PONSE (trÃ¨s amÃ©liorÃ©e)
                try:
                    if hasattr(message.server_content, 'model_turn') and message.server_content.model_turn:
                        model_turn = message.server_content.model_turn
                        
                        for part_idx, part in enumerate(model_turn.parts):
                            if hasattr(part, 'inline_data') and part.inline_data and part.inline_data.data:
                                try:
                                    audio_data = part.inline_data.data
                                    audio_size = len(audio_data)
                                    
                                    # Log sÃ©lectif pour Ã©viter le spam
                                    if part_idx % 10 == 0:
                                        log_debug(f"ğŸ”Š Audio part #{part_idx} reÃ§u ({audio_size} bytes)")
                                    
                                    # Ajouter au buffer pour un rendu fluide
                                    audio_buffer.extend(audio_data)
                                    
                                    # Lecture par chunks pour fluiditÃ©
                                    min_buffer_size = CHUNK * 2  # Buffer minimum rÃ©duit pour moins de latence
                                    while len(audio_buffer) >= min_buffer_size and output_stream and running:
                                        # Extraire un chunk du buffer
                                        chunk_to_play = bytes(audio_buffer[:min_buffer_size])
                                        audio_buffer = audio_buffer[min_buffer_size:]
                                        
                                        # Jouer le chunk
                                        try:
                                            output_stream.write(chunk_to_play)
                                            await asyncio.sleep(0.001)  # Micro-pause pour fluiditÃ©
                                        except Exception as play_error:
                                            log_error(f"âš ï¸ Erreur lecture chunk audio", play_error)
                                            break
                                            
                                except Exception as audio_error:
                                    if running:
                                        log_error(f"âš ï¸ Erreur traitement audio part #{part_idx}", audio_error)
                                        
                        # Jouer le buffer restant Ã  la fin du tour de modÃ¨le
                        if len(audio_buffer) > 0 and output_stream and running:
                            try:
                                # ComplÃ©ter avec du silence si nÃ©cessaire pour alignment
                                while len(audio_buffer) % 2 != 0:
                                    audio_buffer.append(0)
                                    
                                output_stream.write(bytes(audio_buffer))
                                audio_buffer.clear()
                            except Exception as final_audio_error:
                                if running:
                                    log_error("âš ï¸ Erreur lecture buffer final", final_audio_error)
                                    
                except Exception as model_turn_error:
                    log_error("âš ï¸ Erreur traitement model_turn", model_turn_error)
                        
        except asyncio.CancelledError:
            log_info("ğŸ›‘ TÃ¢che de rÃ©ception audio annulÃ©e")
        except Exception as e:
            if running:
                log_error("âŒ Erreur rÃ©ception audio", e)
        finally:
            # Jouer le buffer restant avant fermeture
            if len(audio_buffer) > 0 and output_stream:
                try:
                    while len(audio_buffer) % 2 != 0:
                        audio_buffer.append(0)
                    output_stream.write(bytes(audio_buffer))
                    log_debug(f"ğŸ”Š Buffer final jouÃ© ({len(audio_buffer)} bytes)")
                except Exception as final_error:
                    log_error("âš ï¸ Erreur buffer final", final_error)
                    
            # Fermeture propre du stream
            if output_stream:
                log_debug("ğŸ” Fermeture du stream sortie audio")
                try:
                    output_stream.stop_stream()
                    output_stream.close()
                    log_info("âœ… Stream sortie audio fermÃ©")
                except Exception as close_error:
                    log_error("âš ï¸ Erreur fermeture stream sortie", close_error)
                
    def cleanup(self):
        """Nettoyage des ressources"""
        log_debug("ğŸ§¹ Nettoyage des ressources")
        try:
            self.audio_interface.terminate()
            log_info("âœ… Ressources audio libÃ©rÃ©es")
            print(f"{Fore.GREEN}âœ… Ressources audio libÃ©rÃ©es")
        except Exception as e:
            log_error("âš ï¸ Erreur lors du nettoyage", e)
            print(f"{Fore.RED}âš ï¸ Erreur lors du nettoyage: {e}")

def signal_handler(signum, frame):
    """Gestionnaire pour arrÃªt propre avec Ctrl+C"""
    global running
    log_info("ğŸ›‘ Signal d'arrÃªt reÃ§u")
    print(f"\n{Fore.YELLOW}ğŸ›‘ ArrÃªt de la conversation...")
    running = False

def main():
    """Fonction principale"""
    log_info("ğŸš€ DÃ©marrage de l'application Gemini Live API")
    
    # Configuration directe (variables en dur pour dÃ©veloppement local)
    project_id = GOOGLE_CLOUD_PROJECT
    location = GOOGLE_CLOUD_LOCATION
    
    print(f"{Fore.GREEN}âœ… Configuration chargÃ©e:")
    print(f"{Fore.GREEN}   GOOGLE_CLOUD_PROJECT={project_id}")
    print(f"{Fore.GREEN}   GOOGLE_CLOUD_LOCATION={location}")
    print(f"{Fore.GREEN}   MODEL={MODEL}")
    
    log_debug("Configuration systÃ¨me", {
        'project': project_id,
        'location': location,
        'model': MODEL,
        'python_version': sys.version,
        'working_directory': os.getcwd()
    })
    
    # Configuration du gestionnaire de signal pour Ctrl+C
    signal.signal(signal.SIGINT, signal_handler)
    log_debug("ğŸ”§ Gestionnaire de signal configurÃ©")
    
    # Initialisation et dÃ©marrage
    conversation = None
    try:
        log_debug("ğŸ—ï¸ CrÃ©ation du ConversationManager")
        conversation = ConversationManager()
        
        print(f"{Fore.CYAN}ğŸš€ Initialisation de la conversation avec Gemini Live API")
        print(f"{Fore.CYAN}ğŸ“ Projet: {project_id}")
        print(f"{Fore.CYAN}ğŸŒ RÃ©gion: {location}")
        print(f"{Fore.CYAN}ğŸ¤– ModÃ¨le: {MODEL}")
        
        log_info("â–¶ï¸ Lancement de la conversation")
        asyncio.run(conversation.start_conversation())
        
    except KeyboardInterrupt:
        log_info("ğŸ›‘ Conversation interrompue par l'utilisateur")
        print(f"\n{Fore.YELLOW}ğŸ›‘ Conversation interrompue par l'utilisateur")
    except Exception as e:
        log_error("âŒ Erreur inattendue", e)
        print(f"{Fore.RED}âŒ Erreur inattendue: {e}")
        print(f"{Fore.YELLOW}ğŸ“‹ Consultez le fichier 'gemini_live_debug.log' pour plus de dÃ©tails")
    finally:
        if conversation:
            conversation.cleanup()
        log_info("ğŸ‘‹ Fin de l'application")
        print(f"{Fore.GREEN}ğŸ‘‹ Au revoir !")

if __name__ == "__main__":
    main()